{"cells":[{"cell_type":"markdown","source":["# Timeseries classification with a Transformer model\n","\n","**Author:** [Theodoros Ntakouris](https://github.com/ntakouris)<br>\n","**Date created:** 2021/06/25<br>\n","**Last modified:** 2021/08/05<br>\n","**Description:** This notebook demonstrates how to do timeseries classification using a Transformer model."],"metadata":{"id":"Dx8I7rBIeQ3F"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7oRMuovfKwp","executionInfo":{"status":"ok","timestamp":1653113163482,"user_tz":-120,"elapsed":18072,"user":{"displayName":"Ash","userId":"09419559266861850263"}},"outputId":"9ce20939-85b8-4a0d-eb99-5fcbae25acc1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Introduction\n","\n","This is the Transformer architecture from\n","[Attention Is All You Need](https://arxiv.org/abs/1706.03762),\n","applied to timeseries instead of natural language.\n","\n","This example requires TensorFlow 2.4 or higher.\n","\n","## Load the dataset\n","\n","We are going to use the same dataset and preprocessing as the\n","[TimeSeries Classification from Scratch](https://keras.io/examples/timeseries/timeseries_classification_from_scratch)\n","example."],"metadata":{"id":"tdpMxwYleQ4L"}},{"cell_type":"code","execution_count":5,"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","\n","# def readucr(filename):\n","#     data = np.loadtxt(filename, delimiter=\"\\t\")\n","#     y = data[:, 0]\n","#     x = data[:, 1:]\n","#     return x, y.astype(int)\n","\n","\n","# root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n","\n","# x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n","# x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n","\n","# x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","# x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n","def load_data(data_path):\n","    \"\"\"\n","    Loading of the dataset provided\n","    Edit the code below\n","    \"\"\"\n","    data=pd.read_pickle(data_path)\n","    return data\n","\n","def preprocess_data(data):\n","    \"\"\"\n","    A standard nan removal to be added.\n","    Add more preprocessing steps if needed.\n","    \"\"\"\n","    return data\n","\n","def split_train_test(data):\n","    \"\"\"\n","    Splitting the data into train, test, validation \n","    \"\"\"\n","    train, test = train_test_split(data,test_size=0.4, random_state=42,stratify=data['labels'])\n","    test, val = train_test_split(test,test_size=0.5, random_state=42, stratify=test['labels'])\n","\n","    return train, test, val\n","\n","data = load_data(\"/content/drive/MyDrive/01_Hackathon/data.pkl\")\n","data = preprocess_data(data)\n","\n","train, test, val = split_train_test(data)\n","\n","x_train = np.array(train.dim_0.values.tolist())\n","y_train = np.array(train.labels).astype(int)\n","\n","X_test = np.array(test.dim_0.values.tolist())\n","y_test = np.array(train.labels).astype(int)\n","\n","x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n","\n","n_classes = 2\n","\n","idx = np.random.permutation(len(x_train))\n","x_train = x_train[idx]\n","y_train = y_train[idx]\n","\n","y_train[y_train == -1] = 0\n","y_test[y_test == -1] = 0"],"outputs":[],"metadata":{"id":"PChKxwBkeQ4f","executionInfo":{"status":"ok","timestamp":1653113222556,"user_tz":-120,"elapsed":1252,"user":{"displayName":"Ash","userId":"09419559266861850263"}}}},{"cell_type":"markdown","source":["## Build the model\n","\n","Our model processes a tensor of shape `(batch size, sequence length, features)`,\n","where `sequence length` is the number of time steps and `features` is each input\n","timeseries.\n","\n","You can replace your classification RNN layers with this one: the\n","inputs are fully compatible!"],"metadata":{"id":"v_b1If-0eQ43"}},{"cell_type":"code","execution_count":6,"source":["from tensorflow import keras\n","from tensorflow.keras import layers"],"outputs":[],"metadata":{"id":"nOfXovWXeQ5H","executionInfo":{"status":"ok","timestamp":1653113229842,"user_tz":-120,"elapsed":2160,"user":{"displayName":"Ash","userId":"09419559266861850263"}}}},{"cell_type":"markdown","source":["We include residual connections, layer normalization, and dropout.\n","The resulting layer can be stacked multiple times.\n","\n","The projection layers are implemented through `keras.layers.Conv1D`."],"metadata":{"id":"CcyL4cGmeQ5c"}},{"cell_type":"code","execution_count":7,"source":["\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Normalization and Attention\n","    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n","    x = layers.MultiHeadAttention(\n","        key_dim=head_size, num_heads=num_heads, dropout=dropout\n","    )(x, x)\n","    x = layers.Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Feed Forward Part\n","    x = layers.LayerNormalization(epsilon=1e-6)(res)\n","    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n","    x = layers.Dropout(dropout)(x)\n","    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n","    return x + res\n"],"outputs":[],"metadata":{"id":"hXZmBUhSeQ57","executionInfo":{"status":"ok","timestamp":1653113229843,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ash","userId":"09419559266861850263"}}}},{"cell_type":"markdown","source":["The main part of our model is now complete. We can stack multiple of those\n","`transformer_encoder` blocks and we can also proceed to add the final\n","Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n","layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n","our model down to a vector of features for each data point in the current\n","batch. A common way to achieve this is to use a pooling layer. For\n","this example, a `GlobalAveragePooling1D` layer is sufficient."],"metadata":{"id":"hEHJ98RReQ6F"}},{"cell_type":"code","execution_count":8,"source":["\n","def build_model(\n","    input_shape,\n","    head_size,\n","    num_heads,\n","    ff_dim,\n","    num_transformer_blocks,\n","    mlp_units,\n","    dropout=0,\n","    mlp_dropout=0,\n","):\n","    inputs = keras.Input(shape=input_shape)\n","    x = inputs\n","    for _ in range(num_transformer_blocks):\n","        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n","\n","    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n","    for dim in mlp_units:\n","        x = layers.Dense(dim, activation=\"relu\")(x)\n","        x = layers.Dropout(mlp_dropout)(x)\n","    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","    return keras.Model(inputs, outputs)\n"],"outputs":[],"metadata":{"id":"kwCauTzPeQ6N","executionInfo":{"status":"ok","timestamp":1653113230911,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ash","userId":"09419559266861850263"}}}},{"cell_type":"markdown","source":["## Train and evaluate"],"metadata":{"id":"kKcw6I5IeQ6k"}},{"cell_type":"code","execution_count":null,"source":["input_shape = x_train.shape[1:]\n","\n","model = build_model(\n","    input_shape,\n","    head_size=256,\n","    num_heads=4,\n","    ff_dim=4,\n","    num_transformer_blocks=4,\n","    mlp_units=[128],\n","    mlp_dropout=0.4,\n","    dropout=0.25,\n",")\n","\n","model.compile(\n","    loss=keras.losses.BinaryCrossentropy(),\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","    metrics=keras.metrics.BinaryAccuracy(),\n",")\n","model.summary()\n","\n","callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n","\n","model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    epochs=200,\n","    batch_size=64,\n","    callbacks=callbacks,\n",")\n","\n","model.evaluate(x_test, y_test, verbose=1)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 500, 1)]     0           []                               \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 500, 1)      2           ['input_1[0][0]']                \n"," alization)                                                                                       \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 500, 1)      7169        ['layer_normalization[0][0]',    \n"," dAttention)                                                      'layer_normalization[0][0]']    \n","                                                                                                  \n"," dropout (Dropout)              (None, 500, 1)       0           ['multi_head_attention[0][0]']   \n","                                                                                                  \n"," tf.__operators__.add (TFOpLamb  (None, 500, 1)      0           ['dropout[0][0]',                \n"," da)                                                              'input_1[0][0]']                \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add[0][0]']   \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 500, 4)       8           ['layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 500, 4)       0           ['conv1d[0][0]']                 \n","                                                                                                  \n"," conv1d_1 (Conv1D)              (None, 500, 1)       5           ['dropout_1[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, 500, 1)      0           ['conv1d_1[0][0]',               \n"," mbda)                                                            'tf.__operators__.add[0][0]']   \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_1[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 500, 1)      7169        ['layer_normalization_2[0][0]',  \n"," eadAttention)                                                    'layer_normalization_2[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_1[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  (None, 500, 1)      0           ['dropout_2[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_1[0][0]'] \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_2[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_2 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 500, 4)       0           ['conv1d_2[0][0]']               \n","                                                                                                  \n"," conv1d_3 (Conv1D)              (None, 500, 1)       5           ['dropout_3[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_3 (TFOpLa  (None, 500, 1)      0           ['conv1d_3[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_2[0][0]'] \n","                                                                                                  \n"," layer_normalization_4 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_3[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_2 (MultiH  (None, 500, 1)      7169        ['layer_normalization_4[0][0]',  \n"," eadAttention)                                                    'layer_normalization_4[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_2[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_4 (TFOpLa  (None, 500, 1)      0           ['dropout_4[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_3[0][0]'] \n","                                                                                                  \n"," layer_normalization_5 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_4[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_4 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_5[0][0]']  \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 500, 4)       0           ['conv1d_4[0][0]']               \n","                                                                                                  \n"," conv1d_5 (Conv1D)              (None, 500, 1)       5           ['dropout_5[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_5 (TFOpLa  (None, 500, 1)      0           ['conv1d_5[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_4[0][0]'] \n","                                                                                                  \n"," layer_normalization_6 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_5[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_3 (MultiH  (None, 500, 1)      7169        ['layer_normalization_6[0][0]',  \n"," eadAttention)                                                    'layer_normalization_6[0][0]']  \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_3[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_6 (TFOpLa  (None, 500, 1)      0           ['dropout_6[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_5[0][0]'] \n","                                                                                                  \n"," layer_normalization_7 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_6[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_6 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_7[0][0]']  \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 500, 4)       0           ['conv1d_6[0][0]']               \n","                                                                                                  \n"," conv1d_7 (Conv1D)              (None, 500, 1)       5           ['dropout_7[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_7 (TFOpLa  (None, 500, 1)      0           ['conv1d_7[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_6[0][0]'] \n","                                                                                                  \n"," global_average_pooling1d (Glob  (None, 500)         0           ['tf.__operators__.add_7[0][0]'] \n"," alAveragePooling1D)                                                                              \n","                                                                                                  \n"," dense (Dense)                  (None, 128)          64128       ['global_average_pooling1d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 1)            129         ['dropout_8[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 93,001\n","Trainable params: 93,001\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/200\n","37/37 [==============================] - 32s 476ms/step - loss: 0.8695 - binary_accuracy: 0.5011 - val_loss: 0.6982 - val_binary_accuracy: 0.5753\n","Epoch 2/200\n","37/37 [==============================] - 17s 465ms/step - loss: 0.7638 - binary_accuracy: 0.5553 - val_loss: 0.6558 - val_binary_accuracy: 0.6244\n","Epoch 3/200\n","37/37 [==============================] - 17s 472ms/step - loss: 0.7133 - binary_accuracy: 0.5858 - val_loss: 0.6253 - val_binary_accuracy: 0.6633\n","Epoch 4/200\n","37/37 [==============================] - 18s 477ms/step - loss: 0.6796 - binary_accuracy: 0.6150 - val_loss: 0.6057 - val_binary_accuracy: 0.6904\n","Epoch 5/200\n","37/37 [==============================] - 18s 481ms/step - loss: 0.6453 - binary_accuracy: 0.6379 - val_loss: 0.5925 - val_binary_accuracy: 0.6920\n","Epoch 6/200\n","37/37 [==============================] - 18s 485ms/step - loss: 0.6159 - binary_accuracy: 0.6633 - val_loss: 0.5815 - val_binary_accuracy: 0.6954\n","Epoch 7/200\n","21/37 [================>.............] - ETA: 7s - loss: 0.5977 - binary_accuracy: 0.6838"]}],"metadata":{"id":"yFIB-y26eQ61","outputId":"67a16649-a8cf-4f8f-e83a-47e9d15ffc15","colab":{"base_uri":"https://localhost:8080/"}}},{"cell_type":"markdown","source":["## Conclusions\n","\n","In about 110-120 epochs (25s each on Colab), the model reaches a training\n","accuracy of ~0.95, validation accuracy of ~84 and a testing\n","accuracy of ~85, without hyperparameter tuning. And that is for a model\n","with less than 100k parameters. Of course, parameter count and accuracy could be\n","improved by a hyperparameter search and a more sophisticated learning rate\n","schedule, or a different optimizer.\n","\n","You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/timeseries_transformer_classification) and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/timeseries_transformer_classification)."],"metadata":{"id":"s9OpzqgReQ7M"}},{"cell_type":"code","source":[""],"metadata":{"id":"v8TUf_VwAn5z"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"myCopy of timeseries_transformer_classification","provenance":[{"file_id":"1-zcRJkq-839-xSzgOdKIOwjmZSIPyzZf","timestamp":1653101349659},{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb","timestamp":1653100762133}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}