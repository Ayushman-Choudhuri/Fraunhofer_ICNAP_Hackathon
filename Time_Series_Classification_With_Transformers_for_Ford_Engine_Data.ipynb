{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Flatten,Dropout \n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimenstion_mod(x):\n",
    "    a = list()\n",
    "    for i in range(x.shape[0]):\n",
    "        a.append(x[i])\n",
    "    a = np.array(a) \n",
    "    return np.reshape(a, (a.shape[0], a.shape[1],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(df,target):\n",
    "    X =  df[df.columns.drop(target)].to_numpy()\n",
    "    y = df[target].to_numpy(dtype=int)\n",
    "\n",
    "    y = np.where(y == -1, 0, y)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)\n",
    "\n",
    "    X_train = dimenstion_mod(X_train)\n",
    "    X_val = dimenstion_mod(X_val)\n",
    "    X_test = dimenstion_mod(X_test)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100,\n",
    "                return_sequences=True,\n",
    "                input_shape=(X_train.shape[1],1)))\n",
    "    model.add(LSTM(200, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    #model.add(LSTM(20))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.binary_crossentropy)\n",
    "\n",
    "    history = model.fit(X_train,y_train,epochs=100, validation_data=(X_val, y_val), validation_steps = 20 ,batch_size=100)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.where(y_pred > 0.5,1,0)\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred[:,0])\n",
    "    balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_pred[:,0])\n",
    "    print(cm)\n",
    "\n",
    "    return cm, balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m preprocessed_data\u001b[38;5;241m=\u001b[39mpreprocess_data(data)\n\u001b[1;32m     63\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m timeseries_transform(preprocessed_data)\n\u001b[0;32m---> 64\u001b[0m train,test,val\u001b[38;5;241m=\u001b[39m\u001b[43msplit_train_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m model_self\u001b[38;5;241m=\u001b[39mmodel_training(train,test)\n\u001b[1;32m     66\u001b[0m metrics\u001b[38;5;241m=\u001b[39mmetric(val,model_self)\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36msplit_train_test\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_train_test\u001b[39m(data):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Splitting the data into train, test, validation \u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m train_test_split(data,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,stratify\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     22\u001b[0m     test, val \u001b[38;5;241m=\u001b[39m train_test_split(test,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mtest[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train, test, val\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def load_data(data_path):\n",
    "    \"\"\"\n",
    "    Loading of the dataset provided\n",
    "    Edit the code below\n",
    "    \"\"\"\n",
    "    data=None\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    A standard nan removal to be added.\n",
    "    Add more preprocessing steps if needed.\n",
    "    \"\"\"\n",
    "    return data\n",
    "\n",
    "def split_train_test(data):\n",
    "    \"\"\"\n",
    "    Splitting the data into train, test, validation \n",
    "    \"\"\"\n",
    "    train, test = train_test_split(data,test_size=0.4, random_state=42,stratify=data['labels'])\n",
    "    test, val = train_test_split(test,test_size=0.5, random_state=42, stratify=test['labels'])\n",
    "\n",
    "    return train, test, val\n",
    "\n",
    "def timeseries_transform(data):\n",
    "    \"\"\"\n",
    "    Implement the timeseries transformer here\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "def model_training():\n",
    "    \"\"\"\n",
    "    Train the data with the compatible model\n",
    "    \"\"\"\n",
    "    model=None\n",
    "    return model\n",
    "\n",
    "def metric(validation_data, model):\n",
    "    \"\"\"\n",
    "    Standard metrics and plotting should be same\n",
    "    Metrics should be computed on validation data(unseen data)\n",
    "    1. Balanced accuracy score\n",
    "    2. Confusion matrix\n",
    "    3. Per-class accuracy\n",
    "    \"\"\"\n",
    "    metrics=None\n",
    "    return metrics\n",
    "\n",
    "def validation(metrics, metrics_validation):\n",
    "    \"\"\"\n",
    "    Comparing the results with provided Series Embedder\n",
    "    Plot confusion matrices of self analysis and LSTM with balanced_accuracy\n",
    "    \n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    path=None\n",
    "    data=load_data(path)\n",
    "    preprocessed_data=preprocess_data(data)\n",
    "\n",
    "    transformed_data = timeseries_transform(preprocessed_data)\n",
    "    train,test,val=split_train_test(transformed_data)\n",
    "    model_self=model_training(train,test)\n",
    "    metrics=metric(val,model_self)\n",
    "    \n",
    "    lstm_cm,lstm_balanced_accuracy=lstm(preprocessed_data,target='labels')\n",
    "    metrics_validation = [lstm_cm, lstm_balanced_accuracy]\n",
    "    validation(metrics,metrics_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
