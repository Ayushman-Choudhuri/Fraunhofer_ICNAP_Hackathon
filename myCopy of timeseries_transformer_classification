{"cells":[{"cell_type":"markdown","source":["# Timeseries classification with a Transformer model\n","\n","**Author:** [Theodoros Ntakouris](https://github.com/ntakouris)<br>\n","**Date created:** 2021/06/25<br>\n","**Last modified:** 2021/08/05<br>\n","**Description:** This notebook demonstrates how to do timeseries classification using a Transformer model."],"metadata":{"id":"Dx8I7rBIeQ3F"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7oRMuovfKwp","executionInfo":{"status":"ok","timestamp":1653101498134,"user_tz":-120,"elapsed":60192,"user":{"displayName":"Allwin Lucious","userId":"07631666124098189466"}},"outputId":"7dfe9dec-f5c4-4452-ea52-29253101e346"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Introduction\n","\n","This is the Transformer architecture from\n","[Attention Is All You Need](https://arxiv.org/abs/1706.03762),\n","applied to timeseries instead of natural language.\n","\n","This example requires TensorFlow 2.4 or higher.\n","\n","## Load the dataset\n","\n","We are going to use the same dataset and preprocessing as the\n","[TimeSeries Classification from Scratch](https://keras.io/examples/timeseries/timeseries_classification_from_scratch)\n","example."],"metadata":{"id":"tdpMxwYleQ4L"}},{"cell_type":"code","execution_count":52,"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","\n","# def readucr(filename):\n","#     data = np.loadtxt(filename, delimiter=\"\\t\")\n","#     y = data[:, 0]\n","#     x = data[:, 1:]\n","#     return x, y.astype(int)\n","\n","\n","# root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n","\n","# x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n","# x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n","\n","# x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","# x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n","def load_data(data_path):\n","    \"\"\"\n","    Loading of the dataset provided\n","    Edit the code below\n","    \"\"\"\n","    data=pd.read_pickle(data_path)\n","    return data\n","\n","def preprocess_data(data):\n","    \"\"\"\n","    A standard nan removal to be added.\n","    Add more preprocessing steps if needed.\n","    \"\"\"\n","    return data\n","\n","def split_train_test(data):\n","    \"\"\"\n","    Splitting the data into train, test, validation \n","    \"\"\"\n","    train, test = train_test_split(data,test_size=0.4, random_state=42,stratify=data['labels'])\n","    test, val = train_test_split(test,test_size=0.5, random_state=42, stratify=test['labels'])\n","\n","    return train, test, val\n","\n","data = load_data(\"/content/drive/MyDrive/Colab Notebooks/data.pkl\")\n","data = preprocess_data(data)\n","\n","train, test, val = split_train_test(data)\n","\n","x_train = np.array(train.dim_0.values.tolist())\n","y_train = np.array(train.labels).astype(int)\n","\n","X_test = np.array(test.dim_0.values.tolist())\n","y_test = np.array(train.labels).astype(int)\n","\n","x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n","\n","n_classes = 2\n","\n","idx = np.random.permutation(len(x_train))\n","x_train = x_train[idx]\n","y_train = y_train[idx]\n","\n","y_train[y_train == -1] = 0\n","y_test[y_test == -1] = 0"],"outputs":[],"metadata":{"id":"PChKxwBkeQ4f","executionInfo":{"status":"ok","timestamp":1653106944382,"user_tz":-120,"elapsed":243,"user":{"displayName":"Allwin Lucious","userId":"07631666124098189466"}}}},{"cell_type":"markdown","source":["## Build the model\n","\n","Our model processes a tensor of shape `(batch size, sequence length, features)`,\n","where `sequence length` is the number of time steps and `features` is each input\n","timeseries.\n","\n","You can replace your classification RNN layers with this one: the\n","inputs are fully compatible!"],"metadata":{"id":"v_b1If-0eQ43"}},{"cell_type":"code","execution_count":53,"source":["from tensorflow import keras\n","from tensorflow.keras import layers"],"outputs":[],"metadata":{"id":"nOfXovWXeQ5H","executionInfo":{"status":"ok","timestamp":1653106953078,"user_tz":-120,"elapsed":2073,"user":{"displayName":"Allwin Lucious","userId":"07631666124098189466"}}}},{"cell_type":"markdown","source":["We include residual connections, layer normalization, and dropout.\n","The resulting layer can be stacked multiple times.\n","\n","The projection layers are implemented through `keras.layers.Conv1D`."],"metadata":{"id":"CcyL4cGmeQ5c"}},{"cell_type":"code","execution_count":54,"source":["\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Normalization and Attention\n","    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n","    x = layers.MultiHeadAttention(\n","        key_dim=head_size, num_heads=num_heads, dropout=dropout\n","    )(x, x)\n","    x = layers.Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Feed Forward Part\n","    x = layers.LayerNormalization(epsilon=1e-6)(res)\n","    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n","    x = layers.Dropout(dropout)(x)\n","    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n","    return x + res\n"],"outputs":[],"metadata":{"id":"hXZmBUhSeQ57","executionInfo":{"status":"ok","timestamp":1653106955565,"user_tz":-120,"elapsed":220,"user":{"displayName":"Allwin Lucious","userId":"07631666124098189466"}}}},{"cell_type":"markdown","source":["The main part of our model is now complete. We can stack multiple of those\n","`transformer_encoder` blocks and we can also proceed to add the final\n","Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n","layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n","our model down to a vector of features for each data point in the current\n","batch. A common way to achieve this is to use a pooling layer. For\n","this example, a `GlobalAveragePooling1D` layer is sufficient."],"metadata":{"id":"hEHJ98RReQ6F"}},{"cell_type":"code","execution_count":67,"source":["\n","def build_model(\n","    input_shape,\n","    head_size,\n","    num_heads,\n","    ff_dim,\n","    num_transformer_blocks,\n","    mlp_units,\n","    dropout=0,\n","    mlp_dropout=0,\n","):\n","    inputs = keras.Input(shape=input_shape)\n","    x = inputs\n","    for _ in range(num_transformer_blocks):\n","        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n","\n","    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n","    for dim in mlp_units:\n","        x = layers.Dense(dim, activation=\"relu\")(x)\n","        x = layers.Dropout(mlp_dropout)(x)\n","    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","    return keras.Model(inputs, outputs)\n"],"outputs":[],"metadata":{"id":"kwCauTzPeQ6N","executionInfo":{"status":"ok","timestamp":1653110509773,"user_tz":-120,"elapsed":4,"user":{"displayName":"Allwin Lucious","userId":"07631666124098189466"}}}},{"cell_type":"markdown","source":["## Train and evaluate"],"metadata":{"id":"kKcw6I5IeQ6k"}},{"cell_type":"code","execution_count":null,"source":["input_shape = x_train.shape[1:]\n","\n","model = build_model(\n","    input_shape,\n","    head_size=256,\n","    num_heads=4,\n","    ff_dim=4,\n","    num_transformer_blocks=4,\n","    mlp_units=[128],\n","    mlp_dropout=0.4,\n","    dropout=0.25,\n",")\n","\n","model.compile(\n","    loss=keras.losses.BinaryCrossentropy(),\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","    metrics=keras.metrics.BinaryAccuracy(),\n",")\n","model.summary()\n","\n","callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n","\n","model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    epochs=200,\n","    batch_size=64,\n","    callbacks=callbacks,\n",")\n","\n","model.evaluate(x_test, y_test, verbose=1)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_11\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_12 (InputLayer)          [(None, 500, 1)]     0           []                               \n","                                                                                                  \n"," layer_normalization_88 (LayerN  (None, 500, 1)      2           ['input_12[0][0]']               \n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_44 (Multi  (None, 500, 1)      7169        ['layer_normalization_88[0][0]', \n"," HeadAttention)                                                   'layer_normalization_88[0][0]'] \n","                                                                                                  \n"," dropout_99 (Dropout)           (None, 500, 1)       0           ['multi_head_attention_44[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_88 (TFOpL  (None, 500, 1)      0           ['dropout_99[0][0]',             \n"," ambda)                                                           'input_12[0][0]']               \n","                                                                                                  \n"," layer_normalization_89 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_88[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv1d_88 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_89[0][0]'] \n","                                                                                                  \n"," dropout_100 (Dropout)          (None, 500, 4)       0           ['conv1d_88[0][0]']              \n","                                                                                                  \n"," conv1d_89 (Conv1D)             (None, 500, 1)       5           ['dropout_100[0][0]']            \n","                                                                                                  \n"," tf.__operators__.add_89 (TFOpL  (None, 500, 1)      0           ['conv1d_89[0][0]',              \n"," ambda)                                                           'tf.__operators__.add_88[0][0]']\n","                                                                                                  \n"," layer_normalization_90 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_89[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_45 (Multi  (None, 500, 1)      7169        ['layer_normalization_90[0][0]', \n"," HeadAttention)                                                   'layer_normalization_90[0][0]'] \n","                                                                                                  \n"," dropout_101 (Dropout)          (None, 500, 1)       0           ['multi_head_attention_45[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_90 (TFOpL  (None, 500, 1)      0           ['dropout_101[0][0]',            \n"," ambda)                                                           'tf.__operators__.add_89[0][0]']\n","                                                                                                  \n"," layer_normalization_91 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_90[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv1d_90 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_91[0][0]'] \n","                                                                                                  \n"," dropout_102 (Dropout)          (None, 500, 4)       0           ['conv1d_90[0][0]']              \n","                                                                                                  \n"," conv1d_91 (Conv1D)             (None, 500, 1)       5           ['dropout_102[0][0]']            \n","                                                                                                  \n"," tf.__operators__.add_91 (TFOpL  (None, 500, 1)      0           ['conv1d_91[0][0]',              \n"," ambda)                                                           'tf.__operators__.add_90[0][0]']\n","                                                                                                  \n"," layer_normalization_92 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_91[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_46 (Multi  (None, 500, 1)      7169        ['layer_normalization_92[0][0]', \n"," HeadAttention)                                                   'layer_normalization_92[0][0]'] \n","                                                                                                  \n"," dropout_103 (Dropout)          (None, 500, 1)       0           ['multi_head_attention_46[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_92 (TFOpL  (None, 500, 1)      0           ['dropout_103[0][0]',            \n"," ambda)                                                           'tf.__operators__.add_91[0][0]']\n","                                                                                                  \n"," layer_normalization_93 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_92[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv1d_92 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_93[0][0]'] \n","                                                                                                  \n"," dropout_104 (Dropout)          (None, 500, 4)       0           ['conv1d_92[0][0]']              \n","                                                                                                  \n"," conv1d_93 (Conv1D)             (None, 500, 1)       5           ['dropout_104[0][0]']            \n","                                                                                                  \n"," tf.__operators__.add_93 (TFOpL  (None, 500, 1)      0           ['conv1d_93[0][0]',              \n"," ambda)                                                           'tf.__operators__.add_92[0][0]']\n","                                                                                                  \n"," layer_normalization_94 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_93[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," multi_head_attention_47 (Multi  (None, 500, 1)      7169        ['layer_normalization_94[0][0]', \n"," HeadAttention)                                                   'layer_normalization_94[0][0]'] \n","                                                                                                  \n"," dropout_105 (Dropout)          (None, 500, 1)       0           ['multi_head_attention_47[0][0]']\n","                                                                                                  \n"," tf.__operators__.add_94 (TFOpL  (None, 500, 1)      0           ['dropout_105[0][0]',            \n"," ambda)                                                           'tf.__operators__.add_93[0][0]']\n","                                                                                                  \n"," layer_normalization_95 (LayerN  (None, 500, 1)      2           ['tf.__operators__.add_94[0][0]']\n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv1d_94 (Conv1D)             (None, 500, 4)       8           ['layer_normalization_95[0][0]'] \n","                                                                                                  \n"," dropout_106 (Dropout)          (None, 500, 4)       0           ['conv1d_94[0][0]']              \n","                                                                                                  \n"," conv1d_95 (Conv1D)             (None, 500, 1)       5           ['dropout_106[0][0]']            \n","                                                                                                  \n"," tf.__operators__.add_95 (TFOpL  (None, 500, 1)      0           ['conv1d_95[0][0]',              \n"," ambda)                                                           'tf.__operators__.add_94[0][0]']\n","                                                                                                  \n"," global_average_pooling1d_11 (G  (None, 500)         0           ['tf.__operators__.add_95[0][0]']\n"," lobalAveragePooling1D)                                                                           \n","                                                                                                  \n"," dense_22 (Dense)               (None, 128)          64128       ['global_average_pooling1d_11[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dropout_107 (Dropout)          (None, 128)          0           ['dense_22[0][0]']               \n","                                                                                                  \n"," dense_23 (Dense)               (None, 1)            129         ['dropout_107[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 93,001\n","Trainable params: 93,001\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/200\n","37/37 [==============================] - 24s 568ms/step - loss: 0.8789 - binary_accuracy: 0.5294 - val_loss: 0.6881 - val_binary_accuracy: 0.5685\n","Epoch 2/200\n","37/37 [==============================] - 22s 599ms/step - loss: 0.7884 - binary_accuracy: 0.5536 - val_loss: 0.6460 - val_binary_accuracy: 0.6176\n","Epoch 3/200\n","37/37 [==============================] - 21s 570ms/step - loss: 0.7226 - binary_accuracy: 0.5896 - val_loss: 0.6183 - val_binary_accuracy: 0.6565\n","Epoch 4/200\n","37/37 [==============================] - 20s 551ms/step - loss: 0.6971 - binary_accuracy: 0.6192 - val_loss: 0.5970 - val_binary_accuracy: 0.6768\n","Epoch 5/200\n","37/37 [==============================] - 21s 559ms/step - loss: 0.6566 - binary_accuracy: 0.6413 - val_loss: 0.5825 - val_binary_accuracy: 0.6819\n","Epoch 6/200\n","37/37 [==============================] - 21s 572ms/step - loss: 0.6348 - binary_accuracy: 0.6603 - val_loss: 0.5707 - val_binary_accuracy: 0.6971\n","Epoch 7/200\n","37/37 [==============================] - 21s 567ms/step - loss: 0.6176 - binary_accuracy: 0.6870 - val_loss: 0.5620 - val_binary_accuracy: 0.6937\n","Epoch 8/200\n","37/37 [==============================] - 21s 559ms/step - loss: 0.6031 - binary_accuracy: 0.6722 - val_loss: 0.5507 - val_binary_accuracy: 0.7039\n","Epoch 9/200\n","37/37 [==============================] - 21s 562ms/step - loss: 0.5854 - binary_accuracy: 0.6904 - val_loss: 0.5448 - val_binary_accuracy: 0.7073\n","Epoch 10/200\n","37/37 [==============================] - 21s 567ms/step - loss: 0.5756 - binary_accuracy: 0.6972 - val_loss: 0.5389 - val_binary_accuracy: 0.7191\n","Epoch 11/200\n"," 4/37 [==>...........................] - ETA: 17s - loss: 0.5555 - binary_accuracy: 0.7305"]}],"metadata":{"id":"yFIB-y26eQ61","outputId":"560c8e58-59ee-4a00-d41e-a103319d26b3","colab":{"base_uri":"https://localhost:8080/"}}},{"cell_type":"markdown","source":["## Conclusions\n","\n","In about 110-120 epochs (25s each on Colab), the model reaches a training\n","accuracy of ~0.95, validation accuracy of ~84 and a testing\n","accuracy of ~85, without hyperparameter tuning. And that is for a model\n","with less than 100k parameters. Of course, parameter count and accuracy could be\n","improved by a hyperparameter search and a more sophisticated learning rate\n","schedule, or a different optimizer.\n","\n","You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/timeseries_transformer_classification) and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/timeseries_transformer_classification)."],"metadata":{"id":"s9OpzqgReQ7M"}},{"cell_type":"code","source":[""],"metadata":{"id":"v8TUf_VwAn5z"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"myCopy of timeseries_transformer_classification","provenance":[{"file_id":"1-zcRJkq-839-xSzgOdKIOwjmZSIPyzZf","timestamp":1653101349659},{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb","timestamp":1653100762133}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}